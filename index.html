<!DOCTYPE html>
<html>
<head>
    <title>NoCha leaderboard</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="fontawesome/css/all.css"> <!-- Local FontAwesome CSS -->
    <link href="https://fonts.googleapis.com/css2?family=Aladin&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Scheherazade&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Amiri&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <div class="container">
        <h1>
            <img src="genie_lamp.png" alt="Genie Lamp" style="vertical-align: middle; margin-right: 10px; width: 50px; height: auto;">
            A <span class="nocha">No</span>vel <span class="nocha">Cha</span>llenge for long-context language models
        </h1>
        
        <div class="intro">
            <p><span class="nocha">NoCha</span> measures how well <b>long-context language models</b> can verify claims written about fictional books. Check out our <a href="http://arxiv.org/abs/2406.16264"><i class="fas fa-file-alt"></i> paper</a> and <a href="https://github.com/marzenakrp/nocha/"><i class="fab fa-github"></i> GitHub repo</a> for more details.<br><br>
            <b>About the benchmark:</b> <span class="nocha">NoCha</span> contains 1001 <i>narrative minimal pairs</i> written about recently-published novels, where one claim is true and the other is false. Given the book text and a claim, a model is instructed to verify whether the claim is true or false. The model only gets credit for a pair if it correctly labels both the true and false claim.<br>
        </div>

        <div class="filter-container">
                The default leaderboard view ranks models by their accuracy on pairs that they attempted. Each model can only attempt pairs if the book (1) fits within the model's context window and (2) does not trigger content guardrails. The controls below allow you to fairly compare selected models on the <i>common set</i> of pairs that all selected models attempted.<br><br> 
            <div class="checkbox-container">
                <label class="filter-label">
                    <input type="checkbox" id="all-models-checkbox"> <i class="fas fa-globe"></i> Common set (all)
                </label>
                <label class="filter-label">
                    <input type="checkbox" id="closed-source-checkbox"> <i class="fas fa-lock"></i> Common set (closed-source)
                </label>
                <label class="filter-label">
                    <input type="checkbox" id="open-source-checkbox"> <i class="fas fa-lock-open"></i> Common set (open-weights)
                </label>
            </div>
            <div class="filter-controls">
                <select id="model-selection" class="model-selection" multiple="multiple">
                    <!-- Options will be populated by JavaScript -->
                </select>
                <button onclick="clearFilters()" class="clear-button">clear all filters</button>
            </div>
            
        </div>
        
        <table id="leaderboard">
            <thead id="table-headers">
                <tr>
                    <th class="sortable" onclick="sortTable('model')">Model <span class="sort-arrow" id="model-arrow"></span></th>
                    <th class="sortable" onclick="sortTable('accuracy')">Accuracy <span class="sort-arrow" id="accuracy-arrow"></span></th>
                    <th class="sortable" onclick="sortTable('correct')">Correct <span class="sort-arrow" id="correct-arrow"></span></th>
                    <th class="sortable" onclick="sortTable('attempted')">Attempted <span class="sort-arrow" id="attempted-arrow"></span></th>
                </tr>
            </thead>
            <tbody>
                <!-- Rows will be populated by JavaScript -->
            </tbody>
        </table>
        
        
        
        <div class="caution-flag">
            The <span class="nocha">NoCha</span> dataset will <u>not</u> be publicly released to prevent data contamination. We include a small data sample from public domain books in our <a href="https://github.com/marzenakrp/nocha/"><i class="fab fa-github"></i>GitHub repo</a>. Our team commits to updating the leaderboard with new models and updating the dataset with new books. Please <a href="mailto:nochachallenge@gmail.com"><i class="fas fa-envelope"></i>contact us</a> if you want your model to appear on the leaderboard (API credits are certainly welcome!)
        </div>        
        <br>
        
        <!-- <div class="intro">
            <h2>About</h2>
            <p>Nocha tests the capabilities of <b>long-context models</b> to verify claims about fictional books. The test data consists of true/false <b>narrative minimal pairs</b> about the same event or character (see the example below). Each false claim differs from the true claim in its pair <i>only</i> by the inclusion of false information regarding the same event or entity.
                The model must verify both claims in a pair to be awarded 1 point. We report the accuracy (%) along with the counts of correct answers and total attempts. Below you will find the prompts employed to test the models. Results obtained with the "simplified" prompt are marked as "simple" in the table above.</p>
            <p style="text-align: center; margin-top: 10px;"><i class="fas fa-file-alt"></i> Check out our <a href="https://link-to-your-paper.com" target="_blank">paper</a> for more details about the task.</p>
            <p style="text-align: center; margin-top: 10px;"><i class="fab fa-github"></i> Code and sample data available on <a href="https://github.com/marzenakrp/nocha/" target="_blank">GitHub</a>.</p>
            <h2>Example</h2>
            <img src="webexample.svg" alt="Example of Dataset" style="width:100%; height:auto;">
        </div> -->

        <div class="prompt">
            <h2 class="prompt-header" onclick="togglePrompt('prompt-text')"><i class="fas fa-cogs"></i> Prompt</h2>
            <pre id="prompt-text" class="robotic-text">
You are provided with a context and a statement. Your task is to carefully read the context and then determine whether the statement is true or false.

Answer TRUE if the statement is true in its entirety based on the context provided.
Answer FALSE if any part of the statement is false based on the context provided.

<center>&lt;context&gt; {book text} &lt;/context&gt;</center>

<center>&lt;statement&gt; {claim} &lt;/statement&gt;</center>

&lt;question&gt; Based on the context provided, is the above statement TRUE or FALSE? &lt;/question&gt;

First provide an explanation of your decision-making process in at most one paragraph, and then provide your final answer. Use the following format:

<center>&lt;explanation&gt; YOUR EXPLANATION &lt;/explanation&gt;</center>
<center>&lt;answer&gt; YOUR ANSWER &lt;/answer&gt;</center>
            </pre>
        </div>

        <div class="prompt">
            <h2 class="prompt-header" onclick="togglePrompt('prompt-simple-text')"><i class="fas fa-cogs"></i> Prompt (Simple)</h2>
            <pre id="prompt-simple-text" class="robotic-text">
You are provided with a context and a statement. Your task is to carefully read the context and then determine whether the statement is true or false.

Answer TRUE if the statement is true in its entirety based on the context provided.
Answer FALSE if any part of the statement is false based on the context provided.

<center>&lt;context&gt; {book text} &lt;/context&gt;</center>

<center>&lt;statement&gt; {claim} &lt;/statement&gt;</center>

&lt;question&gt; Based on the context provided, is the above statement TRUE or FALSE? &lt;/question&gt;
            </pre>
        </div>

        <div class="team">
            <h2 class="team-header" onclick="toggleTeam('team-section')"><i class="fas fa-users"></i> Team</h2>
            <div id="team-section" class="team-section">
                    <div class="team-member">
                        <a href="https://marzenakrp.github.io/" target="_blank">
                            <img src="assets/marzena.jpeg" alt="Marzena Karpinska" class="team-img">
                            <p>Marzena Karpinska</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://katherinethai.github.io/" target="_blank">
                            <img src="assets/katherine.png" class="team-img">
                            <p>Katherine Thai</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://mungg.github.io/" target="_blank">
                            <img src="assets/yekyung.jpeg" alt="Yekyung Kim" class="team-img">
                            <p>Yekyung Kim</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://lilakk.github.io/" target="_blank">
                            <img src="assets/yapei.jpeg" alt="Yapei Chang" class="team-img">
                            <p>Yapei Chang</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://kyleclo.com/" target="_blank">
                            <img src="assets/kyle.jpeg" alt="Kyle Lo" class="team-img">
                            <p>Kyle Lo</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://tagoyal.github.io/" target="_blank">
                            <img src="assets/tanya.jpeg" alt="Tanya Goyal" class="team-img">
                            <p>Tanya Goyal</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://people.cs.umass.edu/~miyyer/" target="_blank">
                            <img src="assets/mohit.jpeg" alt="Mohit Iyyer" class="team-img">
                            <p>Mohit Iyyer</p>
                        </a>
                    </div>
                
                <!-- Add more team members as needed -->
            </div>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
    <script src="script.js"></script>
    <script>
        function togglePrompt(id) {
            var promptText = document.getElementById(id);
            if (promptText.style.display === "none") {
                promptText.style.display = "block";
            } else {
                promptText.style.display = "none";
            }
        }

        function toggleTeam(id) {
            var teamSection = document.getElementById(id);
            if (teamSection.style.display === "none") {
                teamSection.style.display = "block";
            } else {
                teamSection.style.display = "none";
            }
        }

        function toggleClosedSource() {
            const checkbox = document.getElementById('closed-source-checkbox');
            const closedSourceModels = ["GPT-4o", "GPT-4-Turbo", "Claude-3-Opus", "Claude-3.5-Sonnet", "Gemini Pro 1.5", "Gemini Flash 1.5"];
            if (checkbox.checked) {
                $('#model-selection').val(closedSourceModels).trigger('change');
            } else {
                $('#model-selection').val(null).trigger('change');
            }
        }

        // Initially hide the prompt texts and team section
        document.getElementById('prompt-text').style.display = 'none';
        document.getElementById('prompt-simple-text').style.display = 'none';
        document.getElementById('team-section').style.display = 'none';
    </script>
</body>
</html>
